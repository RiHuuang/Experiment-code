{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9FqD7KJSMSa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import time\n",
        "import yaml\n",
        "import glob\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Install dependencies if missing\n",
        "def install_libs():\n",
        "    os.system(\"pip install -q ultralytics torchmetrics albumentations thop\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torchvision\n",
        "    import torchvision.transforms as T\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
        "    from torchvision.models.detection.ssd import SSD, DefaultBoxGenerator, SSDHead\n",
        "    from torchvision.models._utils import IntermediateLayerGetter\n",
        "    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "    import albumentations as A\n",
        "except ImportError:\n",
        "    print(\"Installing required libraries...\")\n",
        "    install_libs()\n",
        "    # Retry imports after installation\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torchvision\n",
        "    import torchvision.transforms as T\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
        "    from torchvision.models.detection.ssd import SSD, DefaultBoxGenerator, SSDHead\n",
        "    from torchvision.models._utils import IntermediateLayerGetter\n",
        "    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "    import albumentations as A\n",
        "\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Reproducibility: Set deterministic seeds\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration Paths\n",
        "DRIVE_YAML_PATH = \"/content/drive/MyDrive/Dataset/FINAL_YOLO_SPLIT/dataset.yaml\"\n",
        "LOCAL_DATA_DIR = \"/content/local_dataset\"\n",
        "DATASET_YAML = os.path.join(LOCAL_DATA_DIR, \"dataset.yaml\")\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Copy dataset to local environment for faster I/O\n",
        "if not os.path.exists(LOCAL_DATA_DIR):\n",
        "    print(f\"Copying dataset to {LOCAL_DATA_DIR}...\")\n",
        "    drive_data_dir = os.path.dirname(DRIVE_YAML_PATH)\n",
        "    shutil.copytree(drive_data_dir, LOCAL_DATA_DIR)\n",
        "\n",
        "    # Update path in local YAML file\n",
        "    if os.path.exists(DATASET_YAML):\n",
        "        with open(DATASET_YAML, 'r') as f:\n",
        "            data_conf = yaml.safe_load(f)\n",
        "        data_conf['path'] = LOCAL_DATA_DIR\n",
        "        with open(DATASET_YAML, 'w') as f:\n",
        "            yaml.dump(data_conf, f)\n",
        "    print(\"Dataset copied successfully.\")\n",
        "else:\n",
        "    print(f\"Local dataset found at {LOCAL_DATA_DIR}\")\n",
        "\n",
        "# Class Definitions: 0=Brain (Skipped), 1=CSP, 2=LV\n",
        "ID_MAPPING = {1: 1, 2: 2}\n",
        "CLASS_NAMES = ['CSP', 'LV']\n",
        "NUM_CLASSES = len(CLASS_NAMES) + 1 # +1 for Background class\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 100"
      ],
      "metadata": {
        "id": "m0n70seXZOsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SSDEfficientNetBackbone(nn.Module):\n",
        "    def __init__(self, base_backbone, out_channels_list):\n",
        "        super().__init__()\n",
        "        self.base = base_backbone\n",
        "        c_last = out_channels_list[-1]\n",
        "\n",
        "        # Extra Layers (Lite Version: 256 channels) for multi-scale feature maps\n",
        "        self.extra1 = nn.Sequential(\n",
        "            nn.Conv2d(c_last, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256), nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.extra2 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256), nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.extra3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(256), nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.base(x)\n",
        "        x0, x1, x2 = feats['0'], feats['1'], feats['2']\n",
        "        x3 = self.extra1(x2)\n",
        "        x4 = self.extra2(x3)\n",
        "        x5 = self.extra3(x4)\n",
        "\n",
        "        results = OrderedDict()\n",
        "        results['0'] = x0\n",
        "        results['1'] = x1\n",
        "        results['2'] = x2\n",
        "        results['3'] = x3\n",
        "        results['4'] = x4\n",
        "        results['5'] = x5\n",
        "        return results\n",
        "\n",
        "def get_ssd_efficientnet_b2_model(num_classes):\n",
        "    # Load pre-trained EfficientNetB2 backbone\n",
        "    backbone_raw = efficientnet_b2(weights=EfficientNet_B2_Weights.DEFAULT)\n",
        "\n",
        "    # Extract specific feature layers\n",
        "    return_layers = {'3': '0', '5': '1', '8': '2'}\n",
        "    backbone_base = IntermediateLayerGetter(backbone_raw.features, return_layers=return_layers)\n",
        "\n",
        "    # Determine output channels dynamically\n",
        "    with torch.no_grad():\n",
        "        dummy = torch.randn(1, 3, 300, 300)\n",
        "        feats = backbone_base(dummy)\n",
        "        out_channels = [feats['0'].shape[1], feats['1'].shape[1], feats['2'].shape[1]]\n",
        "\n",
        "    full_out_channels = out_channels + [256, 256, 256]\n",
        "    backbone = SSDEfficientNetBackbone(backbone_base, out_channels)\n",
        "    backbone.out_channels = full_out_channels\n",
        "\n",
        "    # Define Anchor Generator\n",
        "    anchor_generator = DefaultBoxGenerator(\n",
        "        aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
        "        scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05],\n",
        "        steps=[8, 16, 32, 64, 100, 300]\n",
        "    )\n",
        "\n",
        "    head = SSDHead(backbone.out_channels, anchor_generator.num_anchors_per_location(), num_classes)\n",
        "\n",
        "    return SSD(backbone=backbone, anchor_generator=anchor_generator, size=(300, 300), num_classes=num_classes, head=head)"
      ],
      "metadata": {
        "id": "Z72FpkYGZQvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "class YOLODatasetRaw(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, width=320, height=320, mapping=None):\n",
        "        self.img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) + glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "        self.label_dir = label_dir\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.mapping = mapping\n",
        "\n",
        "        self.normalize = T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None: return self.__getitem__((idx + 1) % len(self.img_paths))\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        orig_h, orig_w, _ = image.shape\n",
        "\n",
        "        # Resize and Normalize\n",
        "        image_resized = cv2.resize(image, (self.width, self.height))\n",
        "        image_tensor = self.normalize(image_resized)\n",
        "\n",
        "        # Parse Labels\n",
        "        label_name = os.path.basename(img_path).rsplit('.', 1)[0] + \".txt\"\n",
        "        label_path = os.path.join(self.label_dir, label_name)\n",
        "        boxes, labels = [], []\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f: lines = f.readlines()\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                try:\n",
        "                    raw_id = int(parts[0])\n",
        "                    if self.mapping:\n",
        "                        if raw_id not in self.mapping: continue\n",
        "                        final_id = self.mapping[raw_id]\n",
        "                    else: final_id = raw_id + 1\n",
        "\n",
        "                    x_c, y_c, w, h = map(float, parts[1:])\n",
        "                    # Denormalize & Resize coordinates\n",
        "                    x_c *= orig_w; y_c *= orig_h; w *= orig_w; h *= orig_h\n",
        "                    x_min = (x_c - w/2) * (self.width / orig_w)\n",
        "                    y_min = (y_c - h/2) * (self.height / orig_h)\n",
        "                    x_max = (x_c + w/2) * (self.width / orig_w)\n",
        "                    y_max = (y_c + h/2) * (self.height / orig_h)\n",
        "\n",
        "                    boxes.append([x_min, y_min, x_max, y_max])\n",
        "                    labels.append(final_id)\n",
        "                except: continue\n",
        "\n",
        "        target = {}\n",
        "        if len(boxes) > 0:\n",
        "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        else:\n",
        "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "        return image_tensor, target\n",
        "\n",
        "    def __len__(self): return len(self.img_paths)\n",
        "\n",
        "class YOLODatasetAug(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, width=320, height=320, mapping=None, augment=False):\n",
        "        self.img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) + glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "        self.label_dir = label_dir\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.mapping = mapping\n",
        "        self.augment = augment\n",
        "\n",
        "        # Augmentation Pipeline\n",
        "        if self.augment:\n",
        "            self.transform = A.Compose([\n",
        "                A.Affine(rotate=(-45, 45), shear=(-5, 5), translate_percent=(-0.2, 0.2), scale=(0.4, 1.6), p=1.0),\n",
        "                A.Perspective(scale=(0.01, 0.05), keep_size=True, p=0.5),\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
        "                A.Resize(height=self.height, width=self.width)\n",
        "            ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels'], min_visibility=0.3))\n",
        "        else:\n",
        "            self.transform = A.Compose([\n",
        "                A.Resize(height=self.height, width=self.width)\n",
        "            ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None: return self.__getitem__((idx + 1) % len(self.img_paths))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        orig_h, orig_w, _ = image.shape\n",
        "\n",
        "        label_name = os.path.basename(img_path).rsplit('.', 1)[0] + \".txt\"\n",
        "        label_path = os.path.join(self.label_dir, label_name)\n",
        "        boxes_raw, labels_raw = [], []\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f: lines = f.readlines()\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                try:\n",
        "                    raw_id = int(parts[0])\n",
        "                    if self.mapping:\n",
        "                        if raw_id not in self.mapping: continue\n",
        "                        final_id = self.mapping[raw_id]\n",
        "                    else: final_id = raw_id + 1\n",
        "\n",
        "                    x_c, y_c, w, h = map(float, parts[1:])\n",
        "                    x_c *= orig_w; y_c *= orig_h; w *= orig_w; h *= orig_h\n",
        "                    x_min, y_min = max(0, x_c - w/2), max(0, y_c - h/2)\n",
        "                    x_max, y_max = min(orig_w, x_c + w/2), min(orig_h, y_c + h/2)\n",
        "\n",
        "                    if x_max <= x_min or y_max <= y_min: continue\n",
        "                    boxes_raw.append([x_min, y_min, x_max, y_max])\n",
        "                    labels_raw.append(final_id)\n",
        "                except: continue\n",
        "\n",
        "        # Apply Augmentations\n",
        "        if len(boxes_raw) == 0:\n",
        "            augmented = self.transform(image=image, bboxes=[], class_labels=[])\n",
        "        else:\n",
        "            try:\n",
        "                augmented = self.transform(image=image, bboxes=boxes_raw, class_labels=labels_raw)\n",
        "            except ValueError:\n",
        "                # Fallback if augmentation fails (e.g., box clips out of bounds)\n",
        "                return self.__getitem__((idx + 1) % len(self.img_paths))\n",
        "\n",
        "        image_aug = augmented['image']\n",
        "        boxes_aug = augmented['bboxes']\n",
        "        labels_aug = augmented['class_labels']\n",
        "\n",
        "        image_tensor = torch.from_numpy(image_aug.astype(np.float32) / 255.0).permute(2, 0, 1)\n",
        "        normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        image_tensor = normalize(image_tensor)\n",
        "\n",
        "        target = {}\n",
        "        if len(boxes_aug) > 0:\n",
        "            target[\"boxes\"] = torch.as_tensor(boxes_aug, dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.as_tensor(labels_aug, dtype=torch.int64)\n",
        "        else:\n",
        "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.zeros((0,), dtype=torch.int64)\n",
        "        return image_tensor, target\n",
        "\n",
        "    def __len__(self): return len(self.img_paths)"
      ],
      "metadata": {
        "id": "jAOrG9MuZW8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_map_complete(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Calculates mAP 50-95 (Global) and mAP 50 (Per Class) using TorchMetrics.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    metric_global = MeanAveragePrecision(class_metrics=True).to(device)\n",
        "    metric_50 = MeanAveragePrecision(class_metrics=True, iou_thresholds=[0.5]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            t_clean = [{k: v.to(device) for k, v in t.items() if k in ['boxes', 'labels']} for t in targets]\n",
        "            outputs = model(images)\n",
        "            metric_global.update(outputs, t_clean)\n",
        "            metric_50.update(outputs, t_clean)\n",
        "\n",
        "    res_global = metric_global.compute()\n",
        "    res_50 = metric_50.compute()\n",
        "\n",
        "    return {\n",
        "        'map': res_global['map'].item(),                # Global mAP 50-95\n",
        "        'map_50': res_global['map_50'].item(),          # Global mAP 50\n",
        "        'map_per_class': res_global['map_per_class'],   # Per Class mAP 50-95\n",
        "        'map_50_per_class': res_50['map_per_class']     # Per Class mAP 50\n",
        "    }\n",
        "\n",
        "def evaluate_best_f1(model, dataloader, device, num_classes):\n",
        "    \"\"\"\n",
        "    Calculates Best F1-Score, Precision, and Recall at optimal thresholds.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    class_preds = {i: [] for i in range(1, num_classes)}\n",
        "    class_gt_counts = {i: 0 for i in range(1, num_classes)}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            outputs = model(images)\n",
        "\n",
        "            for i, output in enumerate(outputs):\n",
        "                pred_boxes = output['boxes']\n",
        "                pred_scores = output['scores']\n",
        "                pred_labels = output['labels']\n",
        "\n",
        "                gt_boxes = targets[i]['boxes'].to(device)\n",
        "                gt_labels = targets[i]['labels'].to(device)\n",
        "\n",
        "                for cls_id in range(1, num_classes):\n",
        "                    class_gt_counts[cls_id] += (gt_labels == cls_id).sum().item()\n",
        "\n",
        "                if len(pred_scores) > 0:\n",
        "                    sorted_indices = torch.argsort(pred_scores, descending=True)\n",
        "                    pred_boxes = pred_boxes[sorted_indices]\n",
        "                    pred_scores = pred_scores[sorted_indices]\n",
        "                    pred_labels = pred_labels[sorted_indices]\n",
        "\n",
        "                used_gt_indices = set()\n",
        "                iou_matrix = None\n",
        "                if len(gt_boxes) > 0 and len(pred_boxes) > 0:\n",
        "                    iou_matrix = torchvision.ops.box_iou(pred_boxes, gt_boxes)\n",
        "\n",
        "                for p_idx in range(len(pred_boxes)):\n",
        "                    p_label = pred_labels[p_idx].item()\n",
        "                    p_score = pred_scores[p_idx].item()\n",
        "                    if p_label == 0: continue\n",
        "\n",
        "                    is_tp = False\n",
        "                    if iou_matrix is not None:\n",
        "                        ious = iou_matrix[p_idx]\n",
        "                        if len(ious) > 0:\n",
        "                            max_iou, max_gt_idx = torch.max(ious, dim=0)\n",
        "                            max_gt_idx = max_gt_idx.item()\n",
        "                            if (max_iou > 0.5) and \\\n",
        "                               (gt_labels[max_gt_idx].item() == p_label) and \\\n",
        "                               (max_gt_idx not in used_gt_indices):\n",
        "                                is_tp = True\n",
        "                                used_gt_indices.add(max_gt_idx)\n",
        "\n",
        "                    class_preds[p_label].append((p_score, is_tp))\n",
        "\n",
        "    results = {}\n",
        "    for cls_id in range(1, num_classes):\n",
        "        preds = class_preds[cls_id]\n",
        "        total_gt = class_gt_counts[cls_id]\n",
        "\n",
        "        if len(preds) == 0:\n",
        "            results[cls_id] = {'p': 0.0, 'r': 0.0, 'f1': 0.0, 'thres': 0.0}\n",
        "            continue\n",
        "\n",
        "        preds.sort(key=lambda x: x[0], reverse=True)\n",
        "        preds_np = np.array(preds)\n",
        "        scores = preds_np[:, 0]\n",
        "        tp_status = preds_np[:, 1].astype(int)\n",
        "\n",
        "        tp_cumsum = np.cumsum(tp_status)\n",
        "        fp_cumsum = np.cumsum(1 - tp_status)\n",
        "\n",
        "        precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-16)\n",
        "        recalls = tp_cumsum / total_gt if total_gt > 0 else np.zeros_like(tp_cumsum)\n",
        "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-16)\n",
        "\n",
        "        best_idx = np.argmax(f1_scores)\n",
        "        results[cls_id] = {\n",
        "            'p': precisions[best_idx],\n",
        "            'r': recalls[best_idx],\n",
        "            'f1': f1_scores[best_idx],\n",
        "            'thres': scores[best_idx]\n",
        "        }\n",
        "    return results\n",
        "\n",
        "def evaluate_and_print(model, dataloader, device, class_names, current_epoch, num_epochs):\n",
        "    print(f\"\\nEvaluating Epoch {current_epoch}/{num_epochs}...\")\n",
        "    num_classes = len(class_names) + 1\n",
        "\n",
        "    map_results = evaluate_map_complete(model, dataloader, device)\n",
        "    best_f1_results = evaluate_best_f1(model, dataloader, device, num_classes)\n",
        "\n",
        "    csv_data = []\n",
        "    total_p, total_r, valid_classes = 0, 0, 0\n",
        "\n",
        "    map_50_tensor = map_results['map_50_per_class']\n",
        "    map_50_95_tensor = map_results['map_per_class']\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        cls_id = i + 1\n",
        "\n",
        "        if cls_id in best_f1_results:\n",
        "            res = best_f1_results[cls_id]\n",
        "            precision, recall, f1, thres = res['p'], res['r'], res['f1'], res['thres']\n",
        "        else:\n",
        "            precision, recall, f1, thres = 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "        total_p += precision\n",
        "        total_r += recall\n",
        "        valid_classes += 1\n",
        "\n",
        "        map50 = map_50_tensor[i].item() if i < len(map_50_tensor) else 0.0\n",
        "        map5095 = map_50_95_tensor[i].item() if i < len(map_50_95_tensor) else 0.0\n",
        "\n",
        "        csv_data.append({\n",
        "            \"Class\": class_name,\n",
        "            \"mAP 50\": round(map50, 4),\n",
        "            \"mAP 50-95\": round(map5095, 4),\n",
        "            \"Best F1\": round(f1, 4),\n",
        "            \"Best Conf\": round(thres, 3),\n",
        "            \"Precision\": round(precision, 4),\n",
        "            \"Recall\": round(recall, 4)\n",
        "        })\n",
        "\n",
        "    avg_p = total_p / valid_classes if valid_classes > 0 else 0.0\n",
        "    avg_r = total_r / valid_classes if valid_classes > 0 else 0.0\n",
        "\n",
        "    csv_data.append({\n",
        "        \"Class\": \"GLOBAL (ALL)\",\n",
        "        \"mAP 50\": round(map_results['map_50'], 4),\n",
        "        \"mAP 50-95\": round(map_results['map'], 4),\n",
        "        \"Best F1\": \"-\",\n",
        "        \"Best Conf\": \"-\",\n",
        "        \"Precision\": round(avg_p, 4),\n",
        "        \"Recall\": round(avg_r, 4)\n",
        "    })\n",
        "\n",
        "    df_results = pd.DataFrame(csv_data)\n",
        "    print(f\"\\nVALIDATION RESULTS (Epoch {current_epoch}/{num_epochs})\")\n",
        "    print(\"=\"*95)\n",
        "    print(df_results.to_string(index=False))\n",
        "    print(\"=\"*95)\n",
        "\n",
        "    return {\n",
        "        'map50': map_results['map_50'],\n",
        "        'map': map_results['map'],\n",
        "        'precision': avg_p,\n",
        "        'recall': avg_r\n",
        "    }"
      ],
      "metadata": {
        "id": "Gyu1SDmHZVnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, save_path):\n",
        "    epochs_range = range(1, len(history['loss']) + 1)\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    color = 'tab:red'\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Training Loss', color=color, fontweight='bold')\n",
        "    ax1.plot(epochs_range, history['loss'], color=color, linewidth=2, label='Train Loss')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "    ax1.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel('Validation mAP 50', color=color, fontweight='bold')\n",
        "    ax2.plot(epochs_range, history['map50'], color=color, linewidth=2, marker='o', markersize=4, label='Val mAP 50')\n",
        "\n",
        "    if 'recall' in history:\n",
        "        ax2.plot(epochs_range, history['recall'], color='tab:green', linestyle='--', alpha=0.7, label='Val Recall')\n",
        "\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    plt.title('Training Analysis: Loss vs Accuracy')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    print(f\"Graph saved to: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "def run_training_session(session_name, dataset_train, dataset_val, save_dir):\n",
        "    csv_log_path = os.path.join(save_dir, 'training_log.csv')\n",
        "    print(f\"\\n{'#'*40}\")\n",
        "    print(f\"STARTING TRAINING SESSION: {session_name}\")\n",
        "    print(f\"Save Location: {save_dir}\")\n",
        "    print(f\"{'#'*40}\\n\")\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    train_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "    val_loader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "\n",
        "    model = get_ssd_efficientnet_b2_model(NUM_CLASSES)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.AdamW(params, lr=0.0001, weight_decay=0.0005)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
        "\n",
        "    history = {\n",
        "        'epoch': [], 'loss': [], 'map': [], 'map50': [],\n",
        "        'precision': [], 'recall': [], 'time': []\n",
        "    }\n",
        "    best_map50 = 0.0\n",
        "    patience = 15\n",
        "    patience_counter = 0\n",
        "    best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
        "\n",
        "    print(f\"Log will be saved to: {csv_log_path}\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for images, targets in train_loader:\n",
        "            images = list(image.to(DEVICE) for image in images)\n",
        "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            losses.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += losses.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        metrics = evaluate_and_print(model, val_loader, DEVICE, CLASS_NAMES, epoch+1, NUM_EPOCHS)\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        history['epoch'].append(epoch + 1)\n",
        "        history['loss'].append(avg_loss)\n",
        "        history['map'].append(metrics['map'])\n",
        "        history['map50'].append(metrics['map50'])\n",
        "        history['precision'].append(metrics['precision'])\n",
        "        history['recall'].append(metrics['recall'])\n",
        "        history['time'].append(duration)\n",
        "\n",
        "        pd.DataFrame(history).to_csv(csv_log_path, index=False)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch Summary: Loss: {avg_loss:.4f} | LR: {current_lr:.6f} | Time: {duration:.1f}s\")\n",
        "\n",
        "        # Checkpoint & Early Stopping\n",
        "        if metrics['map50'] > best_map50:\n",
        "            best_map50 = metrics['map50']\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Model Saved! Best mAP50: {best_map50:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"EARLY STOPPING TRIGGERED.\")\n",
        "                break\n",
        "\n",
        "    print(f\"{session_name} Finished.\")\n",
        "\n",
        "    # Save History\n",
        "    history_path = os.path.join(save_dir, \"training_history_finished.json\")\n",
        "    with open(history_path, 'w') as f:\n",
        "        json.dump(history, f)\n",
        "    print(f\"History saved to: {history_path}\")\n",
        "\n",
        "    plot_path = os.path.join(save_dir, \"training_history_finished.png\")\n",
        "    plot_history(history, plot_path)"
      ],
      "metadata": {
        "id": "VFwfXBigZd2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_testing_session(mode='raw'):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"START TESTING SESSION: {mode.upper()} (Best F1 Strategy)\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    save_dir = SAVE_DIR_RAW if mode == 'raw' else SAVE_DIR_TUNED\n",
        "    model_path = os.path.join(save_dir, 'best_model.pth')\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Model not found at: {model_path}\"); return\n",
        "\n",
        "    print(f\"Loading Model: {model_path}\")\n",
        "    model = get_ssd_efficientnet_b2_model(NUM_CLASSES)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE).eval()\n",
        "\n",
        "    print(\"Loading Test Data...\")\n",
        "\n",
        "    if mode == 'raw':\n",
        "        test_ds = YOLODatasetRaw(\n",
        "            os.path.join(LOCAL_DATA_DIR, 'test/images'),\n",
        "            os.path.join(LOCAL_DATA_DIR, 'test/labels'),\n",
        "            mapping=ID_MAPPING\n",
        "        )\n",
        "    else:\n",
        "        test_ds = YOLODatasetAug(\n",
        "            os.path.join(LOCAL_DATA_DIR, 'test/images'),\n",
        "            os.path.join(LOCAL_DATA_DIR, 'test/labels'),\n",
        "            mapping=ID_MAPPING,\n",
        "            augment=False\n",
        "        )\n",
        "\n",
        "    test_loader = DataLoader(test_ds, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(\"Calculating Standard mAP (50 & 50-95)...\")\n",
        "    map_results = evaluate_map_complete(model, test_loader, DEVICE)\n",
        "\n",
        "    print(\"Calculating Best F1-Score & Optimal Thresholds...\")\n",
        "    best_f1_results = evaluate_best_f1(model, test_loader, DEVICE, NUM_CLASSES)\n",
        "\n",
        "    csv_data = []\n",
        "    total_p, total_r, valid_classes = 0, 0, 0\n",
        "\n",
        "    map_50_tensor = map_results['map_50_per_class']\n",
        "    map_50_95_tensor = map_results['map_per_class']\n",
        "\n",
        "    for i, class_name in enumerate(CLASS_NAMES):\n",
        "        cls_id = i + 1\n",
        "\n",
        "        if cls_id in best_f1_results:\n",
        "            res = best_f1_results[cls_id]\n",
        "            precision, recall, f1, thres = res['p'], res['r'], res['f1'], res['thres']\n",
        "        else:\n",
        "            precision, recall, f1, thres = 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "        total_p += precision; total_r += recall; valid_classes += 1\n",
        "\n",
        "        map50 = map_50_tensor[i].item() if i < len(map_50_tensor) else 0.0\n",
        "        map5095 = map_50_95_tensor[i].item() if i < len(map_50_95_tensor) else 0.0\n",
        "\n",
        "        csv_data.append({\n",
        "            \"Class\": class_name,\n",
        "            \"mAP 50\": round(map50, 4),\n",
        "            \"mAP 50-95\": round(map5095, 4),\n",
        "            \"Best F1\": round(f1, 4),\n",
        "            \"Best Conf\": round(thres, 3),\n",
        "            \"Precision\": round(precision, 4),\n",
        "            \"Recall\": round(recall, 4)\n",
        "        })\n",
        "\n",
        "    avg_p = total_p / valid_classes if valid_classes > 0 else 0.0\n",
        "    avg_r = total_r / valid_classes if valid_classes > 0 else 0.0\n",
        "\n",
        "    csv_data.append({\n",
        "        \"Class\": \"GLOBAL (ALL)\",\n",
        "        \"mAP 50\": round(map_results['map_50'], 4),\n",
        "        \"mAP 50-95\": round(map_results['map'], 4),\n",
        "        \"Best F1\": \"-\",\n",
        "        \"Best Conf\": \"-\",\n",
        "        \"Precision\": round(avg_p, 4),\n",
        "        \"Recall\": round(avg_r, 4)\n",
        "    })\n",
        "\n",
        "    df_results = pd.DataFrame(csv_data)\n",
        "    out_csv = os.path.join(save_dir, 'ssd_final_test_results_best_f1.csv')\n",
        "    df_results.to_csv(out_csv, index=False)\n",
        "\n",
        "    print(\"\\nTEST COMPLETE. Results saved to:\")\n",
        "    print(f\"{out_csv}\")\n",
        "    print(\"=\"*85)\n",
        "    print(df_results.to_string(index=False))\n",
        "    print(\"=\"*85 + \"\\n\")\n",
        "\n",
        "    del model, test_loader\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_testing_session('raw')\n",
        "    run_testing_session('tuned')"
      ],
      "metadata": {
        "id": "WjvxgEVmZgQ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}