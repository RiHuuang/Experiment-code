{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import time\n",
        "import yaml\n",
        "import json\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Install dependencies if missing\n",
        "def install_dependencies():\n",
        "    os.system(\"pip install -q ultralytics torchmetrics albumentations\")\n",
        "\n",
        "try:\n",
        "    import torchmetrics\n",
        "    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "    import albumentations as A\n",
        "except ImportError:\n",
        "    print(\"Installing dependencies...\")\n",
        "    install_dependencies()\n",
        "    import torchmetrics\n",
        "    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "    import albumentations as A\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection import ssd300_vgg16\n",
        "from torchvision.models.detection.ssd import SSD300_VGG16_Weights, SSDHead\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Reproducibility Setup\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Configuration\n",
        "BASE_DRIVE_DIR = \"/content/drive/MyDrive/\"\n",
        "DRIVE_YAML_PATH = os.path.join(BASE_DRIVE_DIR, \"Dataset/FINAL_YOLO_SPLIT/dataset.yaml\")\n",
        "LOCAL_DATA_DIR = \"/content/local_dataset\"\n",
        "DATASET_YAML = os.path.join(LOCAL_DATA_DIR, \"dataset.yaml\")\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Computation Device: {DEVICE}\")\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 100\n",
        "CLASS_NAMES = ['CSP', 'LV']\n",
        "NUM_CLASSES = len(CLASS_NAMES) + 1  # +1 for Background\n",
        "ID_MAPPING = {1: 1, 2: 2}"
      ],
      "metadata": {
        "id": "ZWrRNfuyh5_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(LOCAL_DATA_DIR):\n",
        "    print(f\"Copying dataset to local runtime: {LOCAL_DATA_DIR}...\")\n",
        "    try:\n",
        "        drive_data_dir = os.path.dirname(DRIVE_YAML_PATH)\n",
        "        shutil.copytree(drive_data_dir, LOCAL_DATA_DIR)\n",
        "\n",
        "        # Update local dataset configuration\n",
        "        if os.path.exists(DATASET_YAML):\n",
        "            with open(DATASET_YAML, 'r') as f:\n",
        "                data_conf = yaml.safe_load(f)\n",
        "            data_conf['path'] = LOCAL_DATA_DIR\n",
        "            with open(DATASET_YAML, 'w') as f:\n",
        "                yaml.dump(data_conf, f)\n",
        "        print(\"Dataset setup complete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up dataset: {e}\")\n",
        "else:\n",
        "    print(f\"Local dataset found at {LOCAL_DATA_DIR}.\")"
      ],
      "metadata": {
        "id": "_6uZ4gLch7tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLODatasetForSSD_Raw(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, width=300, height=300, mapping=None):\n",
        "        self.img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) +\n",
        "                                glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "        self.label_dir = label_dir\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.mapping = mapping\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            return self.__getitem__((idx + 1) % len(self.img_paths))\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        orig_h, orig_w, _ = image.shape\n",
        "\n",
        "        image_resized = cv2.resize(image, (self.width, self.height))\n",
        "        image_tensor = torch.from_numpy(image_resized / 255.0).permute(2, 0, 1)\n",
        "\n",
        "        label_name = os.path.basename(img_path).rsplit('.', 1)[0] + \".txt\"\n",
        "        label_path = os.path.join(self.label_dir, label_name)\n",
        "        boxes, labels = [], []\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                try:\n",
        "                    raw_id = int(parts[0])\n",
        "                    if self.mapping:\n",
        "                        if raw_id in self.mapping:\n",
        "                            final_id = self.mapping[raw_id]\n",
        "                        else:\n",
        "                            continue\n",
        "                    else:\n",
        "                        final_id = raw_id + 1\n",
        "\n",
        "                    x_c, y_c, w, h = map(float, parts[1:])\n",
        "                    x_c *= orig_w; y_c *= orig_h; w *= orig_w; h *= orig_h\n",
        "                    x_min = (x_c - w/2) * (self.width / orig_w)\n",
        "                    y_min = (y_c - h/2) * (self.height / orig_h)\n",
        "                    x_max = (x_c + w/2) * (self.width / orig_w)\n",
        "                    y_max = (y_c + h/2) * (self.height / orig_h)\n",
        "\n",
        "                    boxes.append([x_min, y_min, x_max, y_max])\n",
        "                    labels.append(final_id)\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "        target = {}\n",
        "        if len(boxes) > 0:\n",
        "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        else:\n",
        "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "        return image_tensor, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "\n",
        "class YOLODatasetForSSD_Tuned(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, width=300, height=300, mapping=None, augment=False):\n",
        "        self.img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.jpg\")) +\n",
        "                                glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "        self.label_dir = label_dir\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.mapping = mapping\n",
        "        self.augment = augment\n",
        "\n",
        "        if self.augment:\n",
        "            self.transform = A.Compose([\n",
        "                A.Affine(rotate=(-45, 45), shear=(-5, 5), translate_percent=(-0.2, 0.2), scale=(0.4, 1.6), p=1.0),\n",
        "                A.Perspective(scale=(0.01, 0.05), keep_size=True, p=0.5),\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
        "                A.Resize(height=self.height, width=self.width)\n",
        "            ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels'], min_visibility=0.3))\n",
        "        else:\n",
        "            self.transform = A.Compose([\n",
        "                A.Resize(height=self.height, width=self.width)\n",
        "            ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            return self.__getitem__((idx + 1) % len(self.img_paths))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        orig_h, orig_w, _ = image.shape\n",
        "\n",
        "        label_name = os.path.basename(img_path).rsplit('.', 1)[0] + \".txt\"\n",
        "        label_path = os.path.join(self.label_dir, label_name)\n",
        "        boxes_raw, labels_raw = [], []\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                try:\n",
        "                    raw_id = int(parts[0])\n",
        "                    if self.mapping:\n",
        "                        if raw_id in self.mapping:\n",
        "                            final_id = self.mapping[raw_id]\n",
        "                        else:\n",
        "                            continue\n",
        "                    else:\n",
        "                        final_id = raw_id + 1\n",
        "\n",
        "                    x_c, y_c, w, h = map(float, parts[1:])\n",
        "                    x_c *= orig_w; y_c *= orig_h; w *= orig_w; h *= orig_h\n",
        "                    x_min = max(0, x_c - (w/2))\n",
        "                    y_min = max(0, y_c - (h/2))\n",
        "                    x_max = min(orig_w, x_c + (w/2))\n",
        "                    y_max = min(orig_h, y_c + (h/2))\n",
        "\n",
        "                    if x_max <= x_min or y_max <= y_min: continue\n",
        "                    boxes_raw.append([x_min, y_min, x_max, y_max])\n",
        "                    labels_raw.append(final_id)\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "        if len(boxes_raw) == 0:\n",
        "            augmented = self.transform(image=image, bboxes=[], class_labels=[])\n",
        "        else:\n",
        "            try:\n",
        "                augmented = self.transform(image=image, bboxes=boxes_raw, class_labels=labels_raw)\n",
        "            except ValueError:\n",
        "                return self.__getitem__((idx + 1) % len(self.img_paths))\n",
        "\n",
        "        image_tensor = torch.from_numpy(augmented['image'].astype(np.float32) / 255.0).permute(2, 0, 1)\n",
        "        target = {}\n",
        "        if len(augmented['bboxes']) > 0:\n",
        "            target[\"boxes\"] = torch.as_tensor(augmented['bboxes'], dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.as_tensor(augmented['class_labels'], dtype=torch.int64)\n",
        "        else:\n",
        "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "        return image_tensor, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "tBQMEl7wh8kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_map_complete(model, dataloader, device):\n",
        "    model.eval()\n",
        "    metric_global = MeanAveragePrecision(class_metrics=True).to(device)\n",
        "    metric_50 = MeanAveragePrecision(class_metrics=True, iou_thresholds=[0.5]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            t_clean = [{k: v.to(device) for k, v in t.items() if k in ['boxes', 'labels']} for t in targets]\n",
        "            outputs = model(images)\n",
        "            metric_global.update(outputs, t_clean)\n",
        "            metric_50.update(outputs, t_clean)\n",
        "\n",
        "    res_global = metric_global.compute()\n",
        "    res_50 = metric_50.compute()\n",
        "\n",
        "    return {\n",
        "        'map': res_global['map'].item(),\n",
        "        'map_50': res_global['map_50'].item(),\n",
        "        'map_per_class': res_global['map_per_class'],\n",
        "        'map_50_per_class': res_50['map_per_class']\n",
        "    }\n",
        "\n",
        "def evaluate_best_f1(model, dataloader, device, num_classes):\n",
        "    model.eval()\n",
        "    class_preds = {i: [] for i in range(1, num_classes)}\n",
        "    class_gt_counts = {i: 0 for i in range(1, num_classes)}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            outputs = model(images)\n",
        "\n",
        "            for i, output in enumerate(outputs):\n",
        "                pred_boxes = output['boxes']\n",
        "                pred_scores = output['scores']\n",
        "                pred_labels = output['labels']\n",
        "                gt_boxes = targets[i]['boxes'].to(device)\n",
        "                gt_labels = targets[i]['labels'].to(device)\n",
        "\n",
        "                for cls_id in range(1, num_classes):\n",
        "                    class_gt_counts[cls_id] += (gt_labels == cls_id).sum().item()\n",
        "\n",
        "                if len(pred_scores) > 0:\n",
        "                    sorted_indices = torch.argsort(pred_scores, descending=True)\n",
        "                    pred_boxes = pred_boxes[sorted_indices]\n",
        "                    pred_scores = pred_scores[sorted_indices]\n",
        "                    pred_labels = pred_labels[sorted_indices]\n",
        "\n",
        "                used_gt_indices = set()\n",
        "                iou_matrix = None\n",
        "                if len(gt_boxes) > 0 and len(pred_boxes) > 0:\n",
        "                    iou_matrix = torchvision.ops.box_iou(pred_boxes, gt_boxes)\n",
        "\n",
        "                for p_idx in range(len(pred_boxes)):\n",
        "                    p_label = pred_labels[p_idx].item()\n",
        "                    p_score = pred_scores[p_idx].item()\n",
        "                    if p_label == 0: continue\n",
        "\n",
        "                    is_tp = False\n",
        "                    if iou_matrix is not None:\n",
        "                        ious = iou_matrix[p_idx]\n",
        "                        if len(ious) > 0:\n",
        "                            max_iou, max_gt_idx = torch.max(ious, dim=0)\n",
        "                            max_gt_idx = max_gt_idx.item()\n",
        "                            if (max_iou > 0.5) and \\\n",
        "                               (gt_labels[max_gt_idx].item() == p_label) and \\\n",
        "                               (max_gt_idx not in used_gt_indices):\n",
        "                                is_tp = True\n",
        "                                used_gt_indices.add(max_gt_idx)\n",
        "\n",
        "                    class_preds[p_label].append((p_score, is_tp))\n",
        "\n",
        "    results = {}\n",
        "    for cls_id in range(1, num_classes):\n",
        "        preds = class_preds[cls_id]\n",
        "        total_gt = class_gt_counts[cls_id]\n",
        "\n",
        "        if len(preds) == 0:\n",
        "            results[cls_id] = {'p': 0.0, 'r': 0.0, 'f1': 0.0, 'thres': 0.0}\n",
        "            continue\n",
        "\n",
        "        preds.sort(key=lambda x: x[0], reverse=True)\n",
        "        preds_np = np.array(preds)\n",
        "        scores = preds_np[:, 0]\n",
        "        tp_status = preds_np[:, 1].astype(int)\n",
        "\n",
        "        tp_cumsum = np.cumsum(tp_status)\n",
        "        fp_cumsum = np.cumsum(1 - tp_status)\n",
        "\n",
        "        precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-16)\n",
        "        recalls = tp_cumsum / total_gt if total_gt > 0 else np.zeros_like(tp_cumsum)\n",
        "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-16)\n",
        "\n",
        "        best_idx = np.argmax(f1_scores)\n",
        "        results[cls_id] = {\n",
        "            'p': precisions[best_idx],\n",
        "            'r': recalls[best_idx],\n",
        "            'f1': f1_scores[best_idx],\n",
        "            'thres': scores[best_idx]\n",
        "        }\n",
        "    return results\n",
        "\n",
        "def evaluate_and_print(model, dataloader, device, class_names, current_epoch, num_epochs):\n",
        "    print(f\"\\nEvaluating Epoch {current_epoch}/{num_epochs}...\")\n",
        "    num_classes = len(class_names) + 1\n",
        "\n",
        "    map_results = evaluate_map_complete(model, dataloader, device)\n",
        "    best_f1_results = evaluate_best_f1(model, dataloader, device, num_classes)\n",
        "\n",
        "    csv_data = []\n",
        "    total_p, total_r, valid_classes = 0, 0, 0\n",
        "\n",
        "    map_50_tensor = map_results['map_50_per_class']\n",
        "    map_50_95_tensor = map_results['map_per_class']\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        cls_id = i + 1\n",
        "        if cls_id in best_f1_results:\n",
        "            res = best_f1_results[cls_id]\n",
        "            precision, recall, f1, thres = res['p'], res['r'], res['f1'], res['thres']\n",
        "        else:\n",
        "            precision, recall, f1, thres = 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "        total_p += precision\n",
        "        total_r += recall\n",
        "        valid_classes += 1\n",
        "\n",
        "        map50 = map_50_tensor[i].item() if i < len(map_50_tensor) else 0.0\n",
        "        map5095 = map_50_95_tensor[i].item() if i < len(map_50_95_tensor) else 0.0\n",
        "\n",
        "        csv_data.append({\n",
        "            \"Class\": class_name,\n",
        "            \"mAP 50\": round(map50, 4),\n",
        "            \"mAP 50-95\": round(map5095, 4),\n",
        "            \"Best F1\": round(f1, 4),\n",
        "            \"Best Conf\": round(thres, 3),\n",
        "            \"Precision\": round(precision, 4),\n",
        "            \"Recall\": round(recall, 4)\n",
        "        })\n",
        "\n",
        "    avg_p = total_p / valid_classes if valid_classes > 0 else 0.0\n",
        "    avg_r = total_r / valid_classes if valid_classes > 0 else 0.0\n",
        "\n",
        "    csv_data.append({\n",
        "        \"Class\": \"GLOBAL (ALL)\",\n",
        "        \"mAP 50\": round(map_results['map_50'], 4),\n",
        "        \"mAP 50-95\": round(map_results['map'], 4),\n",
        "        \"Best F1\": \"-\",\n",
        "        \"Best Conf\": \"-\",\n",
        "        \"Precision\": round(avg_p, 4),\n",
        "        \"Recall\": round(avg_r, 4)\n",
        "    })\n",
        "\n",
        "    df_results = pd.DataFrame(csv_data)\n",
        "    print(f\"\\nVALIDATION RESULTS (Epoch {current_epoch}/{num_epochs})\")\n",
        "    print(\"=\"*95)\n",
        "    print(df_results.to_string(index=False))\n",
        "    print(\"=\"*95)\n",
        "\n",
        "    return {\n",
        "        'map50': map_results['map_50'],\n",
        "        'map': map_results['map'],\n",
        "        'precision': avg_p,\n",
        "        'recall': avg_r\n",
        "    }"
      ],
      "metadata": {
        "id": "QRJc3Welh-Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ssd_model(num_classes):\n",
        "    print(\"Loading SSD300 VGG16 Pretrained Model...\")\n",
        "    model = ssd300_vgg16(weights=SSD300_VGG16_Weights.DEFAULT)\n",
        "    in_channels = [512, 1024, 512, 256, 256, 256]\n",
        "    num_anchors = model.anchor_generator.num_anchors_per_location()\n",
        "    model.head = SSDHead(in_channels, num_anchors, num_classes)\n",
        "    return model\n",
        "\n",
        "def plot_history(history, save_path):\n",
        "    epochs_range = range(1, len(history['loss']) + 1)\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    color = 'tab:red'\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Training Loss', color=color, fontweight='bold')\n",
        "    ax1.plot(epochs_range, history['loss'], color=color, linewidth=2, label='Train Loss')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "    ax1.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel('Validation mAP 50', color=color, fontweight='bold')\n",
        "    ax2.plot(epochs_range, history['map50'], color=color, linewidth=2, marker='o', markersize=4, label='Val mAP 50')\n",
        "\n",
        "    if 'recall' in history:\n",
        "        ax2.plot(epochs_range, history['recall'], color='tab:green', linestyle='--', alpha=0.7, label='Val Recall')\n",
        "\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    plt.title('Training Analysis: Loss vs Accuracy')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)\n",
        "    print(f\"Graph saved to: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "def run_training_session(session_name, dataset_train, dataset_val, save_dir):\n",
        "    csv_log_path = os.path.join(save_dir, 'training_log.csv')\n",
        "    print(f\"\\n{'#'*40}\")\n",
        "    print(f\"STARTING SESSION: {session_name}\")\n",
        "    print(f\"Save Directory: {save_dir}\")\n",
        "    print(f\"{'#'*40}\\n\")\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    train_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "    val_loader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "\n",
        "    model = get_ssd_model(NUM_CLASSES)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.AdamW(params, lr=0.0001, weight_decay=0.0005)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
        "\n",
        "    history = {\n",
        "        'epoch': [], 'loss': [], 'map': [], 'map50': [],\n",
        "        'precision': [], 'recall': [], 'time': []\n",
        "    }\n",
        "    best_map50 = 0.0\n",
        "    patience = 15\n",
        "    patience_counter = 0\n",
        "    best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
        "\n",
        "    print(f\"Logging metrics to: {csv_log_path}\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for images, targets in train_loader:\n",
        "            images = list(image.to(DEVICE) for image in images)\n",
        "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            losses.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += losses.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        metrics = evaluate_and_print(model, val_loader, DEVICE, CLASS_NAMES, epoch+1, NUM_EPOCHS)\n",
        "        duration = time.time() - start_time\n",
        "\n",
        "        history['epoch'].append(epoch + 1)\n",
        "        history['loss'].append(avg_loss)\n",
        "        history['map'].append(metrics['map'])\n",
        "        history['map50'].append(metrics['map50'])\n",
        "        history['precision'].append(metrics['precision'])\n",
        "        history['recall'].append(metrics['recall'])\n",
        "        history['time'].append(duration)\n",
        "\n",
        "        pd.DataFrame(history).to_csv(csv_log_path, index=False)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch Summary: Loss: {avg_loss:.4f} | LR: {current_lr:.6f} | Time: {duration:.1f}s\")\n",
        "\n",
        "        if metrics['map50'] > best_map50:\n",
        "            best_map50 = metrics['map50']\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Model Saved. Best mAP50: {best_map50:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    print(f\"{session_name} Finished.\")\n",
        "\n",
        "    history_path = os.path.join(save_dir, \"training_history_finished.json\")\n",
        "    with open(history_path, 'w') as f:\n",
        "        json.dump(history, f)\n",
        "\n",
        "    plot_path = os.path.join(save_dir, \"training_history_finished.png\")\n",
        "    plot_history(history, plot_path)"
      ],
      "metadata": {
        "id": "9zFYznFgh_n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Raw Dataset\n",
        "SAVE_DIR_RAW = os.path.join(BASE_DRIVE_DIR, \"Model/SSD_VGG16_Raw\")\n",
        "\n",
        "train_ds_raw = YOLODatasetForSSD_Raw(\n",
        "    os.path.join(LOCAL_DATA_DIR, 'train', 'images'),\n",
        "    os.path.join(LOCAL_DATA_DIR, 'train', 'labels'),\n",
        "    mapping=ID_MAPPING\n",
        ")\n",
        "val_ds_raw = YOLODatasetForSSD_Raw(\n",
        "    os.path.join(LOCAL_DATA_DIR, 'val', 'images'),\n",
        "    os.path.join(LOCAL_DATA_DIR, 'val', 'labels'),\n",
        "    mapping=ID_MAPPING\n",
        ")\n",
        "\n",
        "run_training_session(\"RAW_TRAINING\", train_ds_raw, val_ds_raw, SAVE_DIR_RAW)\n",
        "\n",
        "# Experiment 2: Tuned Dataset\n",
        "SAVE_DIR_TUNED = os.path.join(BASE_DRIVE_DIR, \"Model/SSD_VGG16_Tuned\")\n",
        "\n",
        "train_ds_tuned = YOLODatasetForSSD_Tuned(\n",
        "    os.path.join(LOCAL_DATA_DIR, 'train', 'images'),\n",
        "    os.path.join(LOCAL_DATA_DIR, 'train', 'labels'),\n",
        "    mapping=ID_MAPPING,\n",
        "    augment=True\n",
        ")\n",
        "val_ds_tuned = YOLODatasetForSSD_Tuned(\n",
        "    os.path.join(LOCAL_DATA_DIR, 'val', 'images'),\n",
        "    os.path.join(LOCAL_DATA_DIR, 'val', 'labels'),\n",
        "    mapping=ID_MAPPING,\n",
        "    augment=False\n",
        ")\n",
        "\n",
        "run_training_session(\"TUNED_TRAINING\", train_ds_tuned, val_ds_tuned, SAVE_DIR_TUNED)\n",
        "\n",
        "print(\"All experiments completed successfully.\")"
      ],
      "metadata": {
        "id": "BF_oCM43iA_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}