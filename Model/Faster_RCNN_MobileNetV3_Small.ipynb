{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DKzdgQuiyUx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import time\n",
        "import yaml\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Install dependencies if missing\n",
        "def install_dependencies():\n",
        "    os.system(\"pip install -q albumentations==1.4.0 torchmetrics\")\n",
        "\n",
        "try:\n",
        "    import albumentations as A\n",
        "    from albumentations.pytorch import ToTensorV2\n",
        "    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "except ImportError:\n",
        "    print(\"Installing dependencies...\")\n",
        "    install_dependencies()\n",
        "    import albumentations as A\n",
        "    from albumentations.pytorch import ToTensorV2\n",
        "    from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
        "from torchvision.models.detection.backbone_utils import mobilenet_backbone\n",
        "from torchvision.models.detection.faster_rcnn import TwoMLPHead, FastRCNNPredictor\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Reproducibility Setup\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Configuration\n",
        "BASE_SAVE_DIR = \"/content/drive/MyDrive/Model/FasterRCNN_Small\"\n",
        "DRIVE_YAML_PATH = \"/content/drive/MyDrive/Dataset/FINAL_YOLO_SPLIT/dataset.yaml\"\n",
        "LOCAL_DATA_DIR = \"/content/local_dataset\"\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Computation Device: {DEVICE}\")\n",
        "\n",
        "# Class Definitions\n",
        "# YOLO Format: 0=Brain (Ignored), 1=CSP, 2=LV\n",
        "# Model Format: 0=Background, 1=CSP, 2=LV\n",
        "CLASS_NAMES = ['CSP', 'LV']\n",
        "NUM_CLASSES = len(CLASS_NAMES) + 1\n",
        "ID_MAPPING = {1: 1, 2: 2}\n",
        "\n",
        "os.makedirs(BASE_SAVE_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(LOCAL_DATA_DIR):\n",
        "    print(f\"Copying dataset to local runtime: {LOCAL_DATA_DIR}...\")\n",
        "    try:\n",
        "        drive_data_dir = os.path.dirname(DRIVE_YAML_PATH)\n",
        "        shutil.copytree(drive_data_dir, LOCAL_DATA_DIR)\n",
        "        print(\"Dataset setup complete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error copying dataset: {e}\")\n",
        "else:\n",
        "    print(f\"Local dataset found at {LOCAL_DATA_DIR}.\")"
      ],
      "metadata": {
        "id": "4SjfYpJ3i07B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLODataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transforms=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "        self.img_dir = os.path.join(root_dir, split, 'images')\n",
        "        self.label_dir = os.path.join(root_dir, split, 'labels')\n",
        "\n",
        "        # Load images\n",
        "        self.img_files = sorted(glob.glob(os.path.join(self.img_dir, \"*.jpg\")) +\n",
        "                                glob.glob(os.path.join(self.img_dir, \"*.png\")))\n",
        "\n",
        "        # Mapping YOLO classes to Model classes\n",
        "        self.target_mapping = ID_MAPPING\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_files[idx]\n",
        "        file_name = os.path.basename(img_path)\n",
        "        label_file = os.path.splitext(file_name)[0] + \".txt\"\n",
        "        label_path = os.path.join(self.label_dir, label_file)\n",
        "\n",
        "        # Read Image\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            return self.__getitem__((idx + 1) % len(self.img_files))\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        h, w, _ = image.shape\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        # Parse Labels\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                parts = list(map(float, line.strip().split()))\n",
        "                cls_id_raw = int(parts[0])\n",
        "\n",
        "                if cls_id_raw in self.target_mapping:\n",
        "                    final_cls_id = self.target_mapping[cls_id_raw]\n",
        "                    x_c, y_c, bw, bh = parts[1], parts[2], parts[3], parts[4]\n",
        "\n",
        "                    # Convert normalized xywh to absolute xyxy\n",
        "                    x_min = (x_c - bw / 2) * w\n",
        "                    y_min = (y_c - bh / 2) * h\n",
        "                    x_max = (x_c + bw / 2) * w\n",
        "                    y_max = (y_c + bh / 2) * h\n",
        "\n",
        "                    # Clip to image boundaries\n",
        "                    x_min = max(0, x_min)\n",
        "                    y_min = max(0, y_min)\n",
        "                    x_max = min(w, x_max)\n",
        "                    y_max = min(h, y_max)\n",
        "\n",
        "                    if x_max > x_min and y_max > y_min:\n",
        "                        boxes.append([x_min, y_min, x_max, y_max])\n",
        "                        labels.append(final_cls_id)\n",
        "\n",
        "        # Create Tensors\n",
        "        if len(boxes) > 0:\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        else:\n",
        "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "        # Apply Augmentations\n",
        "        if self.transforms:\n",
        "            try:\n",
        "                transformed = self.transforms(image=image, bboxes=boxes, labels=labels)\n",
        "                image = transformed['image']\n",
        "                boxes = torch.as_tensor(transformed['bboxes'], dtype=torch.float32)\n",
        "                labels = torch.as_tensor(transformed['labels'], dtype=torch.int64)\n",
        "            except Exception:\n",
        "                # Fallback if transform fails\n",
        "                image = ToTensorV2()(image=image)[\"image\"]\n",
        "        else:\n",
        "            image = ToTensorV2()(image=image)[\"image\"]\n",
        "\n",
        "        # Final Empty Check\n",
        "        if len(boxes) == 0:\n",
        "             boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "             labels = torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = torch.tensor([idx])\n",
        "\n",
        "        # Calculate Area\n",
        "        if len(boxes) > 0:\n",
        "            target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "            target[\"iscrowd\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "        else:\n",
        "            target[\"area\"] = torch.as_tensor([], dtype=torch.float32)\n",
        "            target[\"iscrowd\"] = torch.as_tensor([], dtype=torch.int64)\n",
        "\n",
        "        # Normalize Image\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            if image.dtype == torch.uint8:\n",
        "                image = image.float() / 255.0\n",
        "\n",
        "        return image, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "7iDdRrMNi3AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms(condition='Raw'):\n",
        "    bbox_params = A.BboxParams(format='pascal_voc', label_fields=['labels'], min_visibility=0.1)\n",
        "\n",
        "    # Base transforms: Resize and conversion to Tensor\n",
        "    base_ops = [\n",
        "        A.Resize(height=640, width=640),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        "\n",
        "    if condition == 'Tuned':\n",
        "        aug_ops = [\n",
        "            A.Affine(\n",
        "                scale=(0.6, 1.4),\n",
        "                translate_percent=(0, 0.2),\n",
        "                rotate=(-45, 45),\n",
        "                shear=(-5, 5),\n",
        "                p=1.0\n",
        "            ),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Perspective(scale=(0.05, 0.1), p=0.5)\n",
        "        ]\n",
        "        return A.Compose(aug_ops + base_ops, bbox_params=bbox_params)\n",
        "    else:\n",
        "        return A.Compose(base_ops, bbox_params=bbox_params)"
      ],
      "metadata": {
        "id": "eu9A4jaHi5rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_mobilenetv3_small(num_classes):\n",
        "    # Load Backbone\n",
        "    backbone = mobilenet_backbone(\n",
        "        backbone_name=\"mobilenet_v3_small\",\n",
        "        weights=\"DEFAULT\",\n",
        "        fpn=True\n",
        "    )\n",
        "    backbone.out_channels = 256\n",
        "\n",
        "    # Dynamic Anchor Configuration\n",
        "    # Runs a dummy input to determine the actual number of feature maps\n",
        "    model_device = next(backbone.parameters()).device\n",
        "    dummy_input = torch.randn(1, 3, 640, 640).to(model_device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        features = backbone(dummy_input)\n",
        "        feature_map_names = list(features.keys())\n",
        "        num_feature_maps = len(feature_map_names)\n",
        "\n",
        "    print(f\"Backbone feature maps detected: {num_feature_maps}\")\n",
        "\n",
        "    # Anchor Generator Setup\n",
        "    base_sizes = [32, 64, 128, 256, 512, 640]\n",
        "    selected_sizes = tuple((s,) for s in base_sizes[:num_feature_maps])\n",
        "    selected_ratios = ((0.5, 1.0, 2.0),) * num_feature_maps\n",
        "\n",
        "    anchor_generator = AnchorGenerator(\n",
        "        sizes=selected_sizes,\n",
        "        aspect_ratios=selected_ratios\n",
        "    )\n",
        "\n",
        "    # RoI Pooler Setup\n",
        "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
        "        featmap_names=feature_map_names,\n",
        "        output_size=7,\n",
        "        sampling_ratio=2\n",
        "    )\n",
        "\n",
        "    # Assemble Model\n",
        "    model = FasterRCNN(\n",
        "        backbone,\n",
        "        num_classes=num_classes,\n",
        "        rpn_anchor_generator=anchor_generator,\n",
        "        box_roi_pool=roi_pooler\n",
        "    )\n",
        "\n",
        "    # Head Optimization (Reduce parameters)\n",
        "    in_channels = backbone.out_channels * 7 * 7\n",
        "    representation_size = 512\n",
        "    model.roi_heads.box_head = TwoMLPHead(in_channels, representation_size)\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(representation_size, num_classes)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "kZanPJkBi76j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_map_complete(model, dataloader, device):\n",
        "    \"\"\"Calculates mAP 50-95 (Global) and mAP 50 (Per Class).\"\"\"\n",
        "    model.eval()\n",
        "    metric_global = MeanAveragePrecision(class_metrics=True).to(device)\n",
        "    metric_50 = MeanAveragePrecision(class_metrics=True, iou_thresholds=[0.5]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            t_clean = [{k: v.to(device) for k, v in t.items() if k in ['boxes', 'labels']} for t in targets]\n",
        "\n",
        "            outputs = model(images)\n",
        "            metric_global.update(outputs, t_clean)\n",
        "            metric_50.update(outputs, t_clean)\n",
        "\n",
        "    res_global = metric_global.compute()\n",
        "    res_50 = metric_50.compute()\n",
        "\n",
        "    return {\n",
        "        'map': res_global['map'].item(),\n",
        "        'map_50': res_global['map_50'].item(),\n",
        "        'map_per_class': res_global['map_per_class'],\n",
        "        'map_50_per_class': res_50['map_per_class']\n",
        "    }\n",
        "\n",
        "def evaluate_best_f1(model, dataloader, device, num_classes):\n",
        "    \"\"\"Calculates Best F1-Score, Precision, and Recall.\"\"\"\n",
        "    model.eval()\n",
        "    class_preds = {i: [] for i in range(1, num_classes)}\n",
        "    class_gt_counts = {i: 0 for i in range(1, num_classes)}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            outputs = model(images)\n",
        "\n",
        "            for i, output in enumerate(outputs):\n",
        "                pred_boxes = output['boxes']\n",
        "                pred_scores = output['scores']\n",
        "                pred_labels = output['labels']\n",
        "                gt_boxes = targets[i]['boxes'].to(device)\n",
        "                gt_labels = targets[i]['labels'].to(device)\n",
        "\n",
        "                for cls_id in range(1, num_classes):\n",
        "                    class_gt_counts[cls_id] += (gt_labels == cls_id).sum().item()\n",
        "\n",
        "                if len(pred_scores) == 0: continue\n",
        "\n",
        "                # Sort predictions\n",
        "                sorted_indices = torch.argsort(pred_scores, descending=True)\n",
        "                pred_boxes = pred_boxes[sorted_indices]\n",
        "                pred_scores = pred_scores[sorted_indices]\n",
        "                pred_labels = pred_labels[sorted_indices]\n",
        "\n",
        "                used_gt_indices = set()\n",
        "                iou_matrix = None\n",
        "                if len(gt_boxes) > 0 and len(pred_boxes) > 0:\n",
        "                    iou_matrix = torchvision.ops.box_iou(pred_boxes, gt_boxes)\n",
        "\n",
        "                for p_idx in range(len(pred_boxes)):\n",
        "                    p_label = pred_labels[p_idx].item()\n",
        "                    p_score = pred_scores[p_idx].item()\n",
        "                    if p_label == 0: continue\n",
        "\n",
        "                    is_tp = False\n",
        "                    if iou_matrix is not None:\n",
        "                        ious = iou_matrix[p_idx]\n",
        "                        if len(ious) > 0:\n",
        "                            max_iou, max_gt_idx = torch.max(ious, dim=0)\n",
        "                            max_gt_idx = max_gt_idx.item()\n",
        "                            if (max_iou > 0.5) and \\\n",
        "                               (gt_labels[max_gt_idx].item() == p_label) and \\\n",
        "                               (max_gt_idx not in used_gt_indices):\n",
        "                                is_tp = True\n",
        "                                used_gt_indices.add(max_gt_idx)\n",
        "\n",
        "                    class_preds[p_label].append((p_score, is_tp))\n",
        "\n",
        "    results = {}\n",
        "    for cls_id in range(1, num_classes):\n",
        "        preds = class_preds[cls_id]\n",
        "        total_gt = class_gt_counts[cls_id]\n",
        "\n",
        "        if len(preds) == 0:\n",
        "            results[cls_id] = {'p': 0.0, 'r': 0.0, 'f1': 0.0, 'thres': 0.0}\n",
        "            continue\n",
        "\n",
        "        preds.sort(key=lambda x: x[0], reverse=True)\n",
        "        preds_np = np.array(preds)\n",
        "        scores = preds_np[:, 0]\n",
        "        tp_status = preds_np[:, 1].astype(int)\n",
        "\n",
        "        tp_cumsum = np.cumsum(tp_status)\n",
        "        fp_cumsum = np.cumsum(1 - tp_status)\n",
        "\n",
        "        precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-16)\n",
        "        recalls = tp_cumsum / total_gt if total_gt > 0 else np.zeros_like(tp_cumsum)\n",
        "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-16)\n",
        "\n",
        "        best_idx = np.argmax(f1_scores)\n",
        "        results[cls_id] = {\n",
        "            'p': precisions[best_idx],\n",
        "            'r': recalls[best_idx],\n",
        "            'f1': f1_scores[best_idx],\n",
        "            'thres': scores[best_idx]\n",
        "        }\n",
        "    return results\n",
        "\n",
        "def evaluate_and_print(model, dataloader, device, class_names, current_epoch, num_epochs):\n",
        "    print(f\"\\nEvaluating Epoch {current_epoch}/{num_epochs}...\")\n",
        "    num_classes = len(class_names) + 1\n",
        "\n",
        "    map_results = evaluate_map_complete(model, dataloader, device)\n",
        "    best_f1_results = evaluate_best_f1(model, dataloader, device, num_classes)\n",
        "\n",
        "    csv_data = []\n",
        "    total_p, total_r, valid_classes = 0, 0, 0\n",
        "\n",
        "    map_50_tensor = map_results['map_50_per_class']\n",
        "    map_50_95_tensor = map_results['map_per_class']\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        cls_id = i + 1\n",
        "\n",
        "        if cls_id in best_f1_results:\n",
        "            res = best_f1_results[cls_id]\n",
        "            precision, recall, f1, thres = res['p'], res['r'], res['f1'], res['thres']\n",
        "        else:\n",
        "            precision, recall, f1, thres = 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "        total_p += precision\n",
        "        total_r += recall\n",
        "        valid_classes += 1\n",
        "\n",
        "        map50 = map_50_tensor[i].item() if i < len(map_50_tensor) else 0.0\n",
        "        map5095 = map_50_95_tensor[i].item() if i < len(map_50_95_tensor) else 0.0\n",
        "\n",
        "        csv_data.append({\n",
        "            \"Class\": class_name,\n",
        "            \"mAP 50\": round(map50, 4),\n",
        "            \"mAP 50-95\": round(map5095, 4),\n",
        "            \"Best F1\": round(f1, 4),\n",
        "            \"Best Conf\": round(thres, 3),\n",
        "            \"Precision\": round(precision, 4),\n",
        "            \"Recall\": round(recall, 4)\n",
        "        })\n",
        "\n",
        "    avg_p = total_p / valid_classes if valid_classes > 0 else 0.0\n",
        "    avg_r = total_r / valid_classes if valid_classes > 0 else 0.0\n",
        "\n",
        "    csv_data.append({\n",
        "        \"Class\": \"GLOBAL (ALL)\",\n",
        "        \"mAP 50\": round(map_results['map_50'], 4),\n",
        "        \"mAP 50-95\": round(map_results['map'], 4),\n",
        "        \"Best F1\": \"-\",\n",
        "        \"Best Conf\": \"-\",\n",
        "        \"Precision\": round(avg_p, 4),\n",
        "        \"Recall\": round(avg_r, 4)\n",
        "    })\n",
        "\n",
        "    df_results = pd.DataFrame(csv_data)\n",
        "    print(f\"\\nVALIDATION RESULTS (Epoch {current_epoch}/{num_epochs})\")\n",
        "    print(\"=\"*95)\n",
        "    print(df_results.to_string(index=False))\n",
        "    print(\"=\"*95)\n",
        "\n",
        "    return {\n",
        "        'map50': map_results['map_50'],\n",
        "        'map': map_results['map'],\n",
        "        'precision': avg_p,\n",
        "        'recall': avg_r\n",
        "    }"
      ],
      "metadata": {
        "id": "rwVikyFxi9Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    loss_total = 0\n",
        "    steps = 0\n",
        "\n",
        "    for images, targets in data_loader:\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "\n",
        "        # Gradient Clipping to prevent explosion\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_total += losses.item()\n",
        "        steps += 1\n",
        "\n",
        "    return loss_total / max(steps, 1)\n",
        "\n",
        "def run_experiment(condition_name, epochs=100, patience=15):\n",
        "    print(f\"\\nSTARTING EXPERIMENT: {condition_name} | Patience: {patience}\")\n",
        "\n",
        "    # Dataset Setup\n",
        "    train_transform = get_transforms(condition=condition_name.split(' ')[0])\n",
        "    val_transform = get_transforms(condition='Raw')\n",
        "\n",
        "    train_ds = YOLODataset(LOCAL_DATA_DIR, split='train', transforms=train_transform)\n",
        "    val_ds = YOLODataset(LOCAL_DATA_DIR, split='val', transforms=val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "    val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "\n",
        "    # Model Setup\n",
        "    model = get_model_mobilenetv3_small(NUM_CLASSES)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.AdamW(params, lr=0.0001, weight_decay=0.0005)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
        "\n",
        "    # Save Setup\n",
        "    save_path = os.path.join(BASE_SAVE_DIR, condition_name)\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    history = []\n",
        "    best_map = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    print(f\"Saving models to: {save_path}\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # Training\n",
        "        train_loss = train_one_epoch(model, optimizer, train_loader, DEVICE, epoch)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | LR: {current_lr:.6f}\")\n",
        "\n",
        "        # Evaluation\n",
        "        eval_metrics = evaluate_and_print(model, val_loader, DEVICE, CLASS_NAMES, epoch+1, epochs)\n",
        "\n",
        "        current_map50 = eval_metrics['map50']\n",
        "        duration = time.time() - epoch_start\n",
        "\n",
        "        # Checkpointing\n",
        "        status_msg = \"\"\n",
        "        if current_map50 > best_map:\n",
        "            best_map = current_map50\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), os.path.join(save_path, \"best_model.pth\"))\n",
        "            status_msg = \"Model Saved!\"\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            status_msg = f\"No improvement for {epochs_no_improve}/{patience} epochs\"\n",
        "\n",
        "        print(f\"Summary: Loss: {train_loss:.4f} | Time: {duration:.1f}s | {status_msg}\")\n",
        "\n",
        "        # Logging\n",
        "        epoch_data = {\n",
        "            'epoch': epoch+1,\n",
        "            'train_loss': train_loss,\n",
        "            'mAP50_Global': current_map50,\n",
        "            'mAP50-95_Global': eval_metrics['map'],\n",
        "            'Precision_BestF1_Avg': eval_metrics['precision'],\n",
        "            'Recall_BestF1_Avg': eval_metrics['recall'],\n",
        "            'Time': duration\n",
        "        }\n",
        "        history.append(epoch_data)\n",
        "        pd.DataFrame(history).to_csv(os.path.join(save_path, \"metrics.csv\"), index=False)\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"\\nEarly stopping triggered. Best mAP50: {best_map:.4f}\")\n",
        "            break\n",
        "\n",
        "    total_duration = (time.time() - total_start_time) / 60\n",
        "    print(f\"\\nTraining Finished. Best mAP50: {best_map:.4f} | Total Time: {total_duration:.1f}m\")\n",
        "    return best_map, total_duration"
      ],
      "metadata": {
        "id": "mbkrNcGJi_Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_results(log_csv_path, title_suffix=\"\"):\n",
        "    if not os.path.exists(log_csv_path):\n",
        "        print(f\"Log file not found: {log_csv_path}\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(log_csv_path)\n",
        "    epochs = df['epoch']\n",
        "\n",
        "    metrics_config = [\n",
        "        ('train_loss', 'Train/Total Loss', '#1f77b4'),\n",
        "        ('Precision_BestF1_Avg', 'Metrics/Precision (Avg)', '#ff7f0e'),\n",
        "        ('Recall_BestF1_Avg', 'Metrics/Recall (Avg)', '#2ca02c'),\n",
        "        ('mAP50_Global', 'Metrics/mAP 50', '#d62728'),\n",
        "        ('mAP50-95_Global', 'Metrics/mAP 50-95', '#9467bd')\n",
        "    ]\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    fig.suptitle(f'Training Results: {title_suffix}', fontsize=16, fontweight='bold')\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    def smooth_curve(scalars, weight=0.6):\n",
        "        last = scalars[0]\n",
        "        smoothed = []\n",
        "        for point in scalars:\n",
        "            smoothed_val = last * weight + (1 - weight) * point\n",
        "            smoothed.append(smoothed_val)\n",
        "            last = smoothed_val\n",
        "        return smoothed\n",
        "\n",
        "    for i, (col_name, title, color) in enumerate(metrics_config):\n",
        "        ax = axes[i]\n",
        "        if col_name in df.columns:\n",
        "            ax.plot(epochs, df[col_name], color=color, alpha=0.3, linewidth=1, label='Raw')\n",
        "            smoothed_data = smooth_curve(df[col_name].values)\n",
        "            ax.plot(epochs, smoothed_data, color=color, linewidth=2.5, label='Smooth')\n",
        "            ax.set_title(title, fontsize=12, fontweight='bold')\n",
        "            ax.set_xlabel('Epochs')\n",
        "            ax.grid(True, linestyle='--', alpha=0.6)\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "\n",
        "    fig.delaxes(axes[5])\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "    save_path = log_csv_path.replace('.csv', '.png')\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    print(f\"Graph saved to: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = []\n",
        "\n",
        "    # Run Raw Experiment\n",
        "    map_raw, time_raw = run_experiment(\"Raw\", epochs=100)\n",
        "    results.append({'Condition': 'Raw', 'mAP': map_raw})\n",
        "\n",
        "    # Run Tuned Experiment\n",
        "    map_tuned, time_tuned = run_experiment(\"Tuned\", epochs=100)\n",
        "    results.append({'Condition': 'Tuned', 'mAP': map_tuned})\n",
        "\n",
        "    # Plot Comparison\n",
        "    df = pd.DataFrame(results)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    bars = plt.bar(df['Condition'], df['mAP'], color=['gray', 'firebrick'])\n",
        "\n",
        "    plt.title(\"Comparison: Faster R-CNN (MobileNetV3)\\nRaw vs Augmented\")\n",
        "    plt.ylabel(\"Mean Average Precision (mAP)\")\n",
        "    plt.ylim(0, 1.1)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                 f'{height:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.savefig(os.path.join(BASE_SAVE_DIR, 'final_result_map.png'))\n",
        "    plt.show()\n",
        "\n",
        "    # Generate Detailed Plots\n",
        "    print(\"\\nDisplaying Raw Results:\")\n",
        "    plot_training_results(os.path.join(BASE_SAVE_DIR, 'Raw', 'metrics.csv'), title_suffix=\"Faster R-CNN (RAW)\")\n",
        "\n",
        "    print(\"\\nDisplaying Tuned Results:\")\n",
        "    plot_training_results(os.path.join(BASE_SAVE_DIR, 'Tuned', 'metrics.csv'), title_suffix=\"Faster R-CNN (TUNED)\")"
      ],
      "metadata": {
        "id": "kvx9pEBVjBGC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}